name: Autonomous Dependency Updater for yt-dlp

on:
  workflow_dispatch:
  schedule:
    - cron: '0 0 */3 * *'

jobs:
  update-dependencies:
    runs-on: ubuntu-latest
    
    defaults:
      run:
        working-directory: ${{ github.workspace }}

    steps:
      - name: Checkout Experiment Repository
        uses: actions/checkout@v4

      - name: Clone yt-dlp Repository
        run: git clone https://github.com/yt-dlp/yt-dlp.git

      - name: Set up Python 3.11
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      # --- THIS IS THE FINAL, CORRECTED, "SMART CACHE" LOGIC ---
      - name: Cache and restore generated-requirements.txt
        id: cache-reqs
        uses: actions/cache@v3
        with:
          path: generated-requirements.txt
          # The key is based on the OS, the text 'reqs-', and a HASH of the pyproject.toml file.
          # If pyproject.toml changes, this key will change, causing a cache miss.
          key: ${{ runner.os }}-reqs-${{ hashFiles('yt-dlp/pyproject.toml') }}

      - name: Generate requirements.txt if cache was missed
        # This step ONLY runs if the cache step above did not find a valid file.
        if: steps.cache-reqs.outputs.cache-hit != 'true'
        run: |
          echo "Cache miss or pyproject.toml changed. Regenerating requirements.txt..."
          python -m pip install pip-tools toml

          python -c "
          import toml; from pathlib import Path
          project_dir = Path('./yt-dlp')
          toml_path = project_dir / 'pyproject.toml'
          data = toml.load(toml_path)
          
          build_deps = data.get('build-system', {}).get('requires', [])
          default_deps = data.get('project', {}).get('optional-dependencies', {}).get('default', [])
          test_deps = data.get('project', {}).get('optional-dependencies', {}).get('test', [])
          all_deps = ['yt-dlp'] + build_deps + default_deps + test_deps
          with open('requirements.in', 'w') as f:
              for dep in all_deps: f.write(f'{dep}\n')
          "
          pip-compile --resolver=backtracking --output-file generated-requirements.txt requirements.in

      # --- The rest of the workflow is now robust ---
      - name: Cache pip packages based on the (potentially new) requirements file
        uses: actions/cache@v3
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('generated-requirements.txt') }}

      - name: Install agent dependencies
        run: pip install google-generativeai pypi-simple packaging

      - name: Run the Autonomous Agent
        run: python dependency_agent.py
        env:
          GEMINI_API_KEY: ${{ secrets.GEMINI_API_KEY }}
      
      - name: Commit and push changes if any
        run: |
          git config --global user.name 'AURA Dependency Agent'
          git config --global user.email 'aura-agent@users.noreply.github.com'
          TARGET_FILE="generated-requirements.txt"
          git add $TARGET_FILE
          if git diff-index --quiet HEAD; then
            echo "No dependency changes to commit."
            exit 0
          fi
          echo "Dependencies have changed. Committing and pushing..."
          git commit -m "chore(deps): Autonomously manage yt-dlp dependencies [skip ci]"
          git push